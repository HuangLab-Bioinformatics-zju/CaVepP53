{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_MODE\"] = \"offline\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "# Imports\n",
    "from transformers import AutoTokenizer, TrainingArguments, Trainer, AutoModelForSequenceClassification,TrainerCallback\n",
    "import torch\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "from datasets import load_dataset, Dataset\n",
    "import scipy.special\n",
    "import os\n",
    "import json\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "# Define the working device\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_labels= 2\n",
    "# Load the model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"chenyuhe/CaVepP53\", trust_remote_code=True)\n",
    "tokenizer=model.tokenizer\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.blocks.35.attn.layernorm_qkv.0.weight\n",
      "transformer.blocks.35.attn.layernorm_qkv.0.bias\n",
      "transformer.blocks.35.attn.layernorm_qkv.1.weight\n",
      "transformer.blocks.35.attn.out_proj.weight\n",
      "transformer.blocks.35.attn.q_ln.weight\n",
      "transformer.blocks.35.attn.k_ln.weight\n",
      "transformer.blocks.35.ffn.0.weight\n",
      "transformer.blocks.35.ffn.0.bias\n",
      "transformer.blocks.35.ffn.1.weight\n",
      "transformer.blocks.35.ffn.3.weight\n",
      "transformer.norm.weight\n",
      "sequence_head.0.weight\n",
      "sequence_head.0.bias\n",
      "sequence_head.2.weight\n",
      "sequence_head.2.bias\n",
      "sequence_head.3.bias\n",
      "classifier.0.weight\n",
      "classifier.0.bias\n",
      "classifier.2.weight\n",
      "classifier.2.bias\n",
      "classifier.3.weight\n",
      "classifier.3.bias\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "# Unfreeze the last n layers\n",
    "# Here, we assume the model has a known number of layers.\n",
    "# You may need to adjust this based on your specific model architecture.\n",
    "last_n_layers = 22\n",
    "for name, param in model.named_parameters():\n",
    "    # Compute the index of the current layer\n",
    "    layer_index = len(list(model.named_parameters())) - list(model.named_parameters()).index((name, param)) - 1\n",
    "    # If the layer index is within the last n layers, unfreeze it\n",
    "    if layer_index < last_n_layers:\n",
    "        param.requires_grad = True\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples in all_data: 3522\n",
      "Train set: 2817\n",
      "Validation set: 352\n",
      "Test set: 353\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af0146d06f2141de846456703394b885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2817 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d289eb98e2d48b4a4fc8a2aa3e5d35e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/352 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0149150756e4925b14009c6a6cd0c5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/353 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from Bio import SeqIO\n",
    "\n",
    "# Load the promoter dataset from the InstaDeep Hugging Face resources\n",
    "# Note: By default, load_dataset(\"csv\") will treat the entire file as a single split (named \"train\").\n",
    "data_file = \"./datas/train_dataset.csv\"  # <-- your path\n",
    "\n",
    "# After loading the data, we get a DatasetDict containing a single split (i.e., dataset[\"train\"]).\n",
    "raw_data = load_dataset(\"csv\", data_files=data_file, encoding=\"utf-8\")\n",
    "all_data = raw_data[\"train\"]\n",
    "# Load the WT sequence\n",
    "TP53_pro = SeqIO.read(r\"./datas/p53_protein_sequence.fasta\", \"fasta\")\n",
    "WT_seq = str(TP53_pro.seq)\n",
    "\n",
    "# Define a function to generate mutant sequences\n",
    "def generate_mut_sequence(row,WT_seq=WT_seq):\n",
    "    pos = row[\"POS\"]\n",
    "    prof = row['REF']\n",
    "    prol = row['ALT']\n",
    "    WT_seq = WT_seq  # Ensure WT_seq is used correctly\n",
    "\n",
    "    # Check if position is out of range or REF does not match\n",
    "    if pos - 1 >= len(WT_seq) or WT_seq[pos - 1] != prof:\n",
    "        print(f\"Error at index {row['id']}: POS out of range or REF mismatch\")  # Print error message\n",
    "        print(row)\n",
    "        return {\"seq\": None}  # Return None for invalid sequences\n",
    "\n",
    "    # Generate mutant sequence\n",
    "    #\n",
    "    left_start = max(0, pos - 26)\n",
    "    right_end = min(len(WT_seq), pos + 25)\n",
    "    left_pad = \"<pad>\" * (26 - (pos - left_start))\n",
    "    right_pad = \"<pad>\" * (25 - (right_end - pos + 1))\n",
    "\n",
    "    mutseq = left_pad + WT_seq[left_start:pos - 1] + prol + WT_seq[pos:right_end] + right_pad\n",
    "    return {\"seq\": mutseq}\n",
    "\n",
    "# Apply the function to each row in the dataset\n",
    "all_data = all_data.map(generate_mut_sequence, batched=False)\n",
    "\n",
    "# Filter out rows with invalid sequences\n",
    "all_data = all_data.filter(lambda row: row['seq'] is not None)\n",
    "\n",
    "print(\"Total samples in all_data:\", len(all_data))\n",
    "\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "train_val_test = all_data.train_test_split(test_size=0.2, seed=42)  # Split into train and temp (20%)\n",
    "train_dataset_raw = train_val_test[\"train\"]\n",
    "val_test_data = train_val_test[\"test\"]\n",
    "\n",
    "val_test_split = val_test_data.train_test_split(test_size=0.5, seed=42)  # Split temp into val and test (50% each)\n",
    "validation_dataset_raw = val_test_split[\"train\"]\n",
    "test_dataset_raw = val_test_split[\"test\"]\n",
    "\n",
    "print(\"Train set:\", len(train_dataset_raw))\n",
    "print(\"Validation set:\", len(validation_dataset_raw))\n",
    "print(\"Test set:\", len(test_dataset_raw))\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = model.tokenizer\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    outputs = tokenizer(examples[\"seq\"], padding=True, return_tensors='pt')\n",
    "    return outputs\n",
    "\n",
    "# Creating tokenized promoter dataset\n",
    "tokenized_datasets_train_promoter = train_dataset_raw.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"seq\", \"Name\", \"REF\", \"ALT\",\"POS\"],\n",
    ")\n",
    "tokenized_datasets_validation_promoter = validation_dataset_raw.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"seq\", \"Name\", \"REF\", \"ALT\",\"POS\"],\n",
    ")\n",
    "tokenized_datasets_test_promoter = test_dataset_raw.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"seq\", \"Name\", \"REF\", \"ALT\",\"POS\"],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huang/anaconda3/envs/ESM/lib/python3.13/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_674057/273578501.py:116: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory. Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 03:01, Epoch 22/23]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.283800</td>\n",
       "      <td>0.206810</td>\n",
       "      <td>0.918768</td>\n",
       "      <td>0.906077</td>\n",
       "      <td>0.931818</td>\n",
       "      <td>0.974511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.235500</td>\n",
       "      <td>0.252604</td>\n",
       "      <td>0.900302</td>\n",
       "      <td>0.961290</td>\n",
       "      <td>0.846591</td>\n",
       "      <td>0.975221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.230400</td>\n",
       "      <td>0.211085</td>\n",
       "      <td>0.919540</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.973090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.212600</td>\n",
       "      <td>0.307105</td>\n",
       "      <td>0.901857</td>\n",
       "      <td>0.845771</td>\n",
       "      <td>0.965909</td>\n",
       "      <td>0.962831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.241900</td>\n",
       "      <td>0.319584</td>\n",
       "      <td>0.866242</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.970841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.202800</td>\n",
       "      <td>0.236346</td>\n",
       "      <td>0.902507</td>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.920455</td>\n",
       "      <td>0.968434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.209100</td>\n",
       "      <td>0.267480</td>\n",
       "      <td>0.890244</td>\n",
       "      <td>0.960526</td>\n",
       "      <td>0.829545</td>\n",
       "      <td>0.971867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.201700</td>\n",
       "      <td>0.262854</td>\n",
       "      <td>0.893983</td>\n",
       "      <td>0.901734</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.961490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.169400</td>\n",
       "      <td>0.242703</td>\n",
       "      <td>0.906433</td>\n",
       "      <td>0.933735</td>\n",
       "      <td>0.880682</td>\n",
       "      <td>0.968000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.168700</td>\n",
       "      <td>0.240618</td>\n",
       "      <td>0.917847</td>\n",
       "      <td>0.915254</td>\n",
       "      <td>0.920455</td>\n",
       "      <td>0.966225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.167800</td>\n",
       "      <td>0.243359</td>\n",
       "      <td>0.910145</td>\n",
       "      <td>0.928994</td>\n",
       "      <td>0.892045</td>\n",
       "      <td>0.967408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.146800</td>\n",
       "      <td>0.234681</td>\n",
       "      <td>0.904899</td>\n",
       "      <td>0.918129</td>\n",
       "      <td>0.892045</td>\n",
       "      <td>0.968000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.146400</td>\n",
       "      <td>0.258615</td>\n",
       "      <td>0.900585</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.964449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.139600</td>\n",
       "      <td>0.240811</td>\n",
       "      <td>0.915452</td>\n",
       "      <td>0.940120</td>\n",
       "      <td>0.892045</td>\n",
       "      <td>0.971433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.135900</td>\n",
       "      <td>0.244150</td>\n",
       "      <td>0.897361</td>\n",
       "      <td>0.927273</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.969381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.246214</td>\n",
       "      <td>0.906433</td>\n",
       "      <td>0.933735</td>\n",
       "      <td>0.880682</td>\n",
       "      <td>0.967645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.125700</td>\n",
       "      <td>0.238352</td>\n",
       "      <td>0.895954</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.880682</td>\n",
       "      <td>0.967961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.120300</td>\n",
       "      <td>0.249009</td>\n",
       "      <td>0.903790</td>\n",
       "      <td>0.928144</td>\n",
       "      <td>0.880682</td>\n",
       "      <td>0.967093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.117100</td>\n",
       "      <td>0.253290</td>\n",
       "      <td>0.904899</td>\n",
       "      <td>0.918129</td>\n",
       "      <td>0.892045</td>\n",
       "      <td>0.965672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.104700</td>\n",
       "      <td>0.243983</td>\n",
       "      <td>0.895954</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.880682</td>\n",
       "      <td>0.967842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "model_name='CaVepP53'\n",
    "args_promoter = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-TP53_51AA\",\n",
    "    remove_unused_columns=False,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    learning_rate=4e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    gradient_accumulation_steps= 1,\n",
    "    per_device_eval_batch_size= 64,\n",
    "    num_train_epochs= 2,\n",
    "    logging_steps= 50,\n",
    "    weight_decay=4e-5,\n",
    "    save_steps = 50,\n",
    "    load_best_model_at_end=True,  # Keep the best model according to the evaluation\n",
    "    metric_for_best_model=\"f1_score\",\n",
    "    label_names=[\"labels\"],\n",
    "    dataloader_drop_last=True,\n",
    "    max_steps= 1000,\n",
    "    seed=42,\n",
    "    save_safetensors=False\n",
    ")\n",
    "\n",
    "# Define the metric for the evaluation using the f1 score\n",
    "def compute_metrics_f1_score(eval_pred):\n",
    "    \"\"\"Computes F1 score for binary classification\"\"\"\n",
    "    logits = eval_pred.predictions[0]\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    references = eval_pred.label_ids\n",
    "    probs = scipy.special.softmax(logits, axis=-1)[:, 1]\n",
    "    r={'f1_score': f1_score(references, predictions),\n",
    "       \"precision\": precision_score(references, predictions),\n",
    "       \"recall\":  recall_score(references, predictions),\n",
    "       \"roc_auc\": roc_auc_score(references, probs)}\n",
    "    return r\n",
    "\n",
    "# A custom callback for logging training/validation metrics and writing them to a JSON file.\n",
    "class MetricsLoggerCallback(TrainerCallback):\n",
    "    def __init__(self, json_file_path=\"training_metrics.json\"):\n",
    "        super().__init__()\n",
    "        self.json_file_path = json_file_path\n",
    "        self.metrics = {\n",
    "            \"train_loss\": [],\n",
    "            \"eval_loss\": [],\n",
    "            \"f1_score\": [],\n",
    "            \"precision\": [],\n",
    "            \"recall\": [],\n",
    "            \"roc_auc\": []\n",
    "        }\n",
    "    \n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Each time the Trainer logs information (i.e., at logging_steps), this section is executed.\n",
    "        The logs contain information such as \"loss\", \"learning_rate\", \"epoch\", etc.\n",
    "        \"\"\"\n",
    "        if logs is None:\n",
    "            return\n",
    "        \n",
    "        # train_loss\n",
    "        if \"loss\" in logs:\n",
    "            self.metrics[\"train_loss\"].append({\n",
    "                \"step\": state.global_step,\n",
    "                \"value\": logs[\"loss\"]\n",
    "            })\n",
    "        \n",
    "        # save json\n",
    "        with open(self.json_file_path, \"w\") as f:\n",
    "            json.dump(self.metrics, f, indent=4)\n",
    "\n",
    "    def on_evaluate(self, args, state, control, metrics=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Each time validation is performed (when evaluation_strategy=\"steps\", \n",
    "        it triggers evaluation every specified number of steps), the execution occurs here.\n",
    "        The metrics contain indicators such as eval_loss, eval_f1_score, eval_precision, and so on.\n",
    "        \"\"\"\n",
    "        if metrics is None:\n",
    "            return\n",
    "        \n",
    "        # eval_loss\n",
    "        if \"eval_loss\" in metrics:\n",
    "            self.metrics[\"eval_loss\"].append({\n",
    "                \"step\": state.global_step,\n",
    "                \"value\": metrics[\"eval_loss\"]\n",
    "            })\n",
    "        # f1\n",
    "        if \"eval_f1_score\" in metrics:\n",
    "            self.metrics[\"f1_score\"].append({\n",
    "                \"step\": state.global_step,\n",
    "                \"value\": metrics[\"eval_f1_score\"]\n",
    "            })\n",
    "        # precision\n",
    "        if \"eval_precision\" in metrics:\n",
    "            self.metrics[\"precision\"].append({\n",
    "                \"step\": state.global_step,\n",
    "                \"value\": metrics[\"eval_precision\"]\n",
    "            })\n",
    "        # recall\n",
    "        if \"eval_recall\" in metrics:\n",
    "            self.metrics[\"recall\"].append({\n",
    "                \"step\": state.global_step,\n",
    "                \"value\": metrics[\"eval_recall\"]\n",
    "            })\n",
    "        # roc_auc\n",
    "        if \"eval_roc_auc\" in metrics:\n",
    "            self.metrics[\"roc_auc\"].append({\n",
    "                \"step\": state.global_step,\n",
    "                \"value\": metrics[\"eval_roc_auc\"]\n",
    "            })\n",
    "        \n",
    "        # save in json\n",
    "        with open(self.json_file_path, \"w\") as f:\n",
    "            json.dump(self.metrics, f, indent=4)\n",
    "\n",
    "            \n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=args_promoter,\n",
    "    train_dataset=tokenized_datasets_train_promoter,\n",
    "    eval_dataset=tokenized_datasets_validation_promoter,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics_f1_score,\n",
    "    callbacks=[MetricsLoggerCallback(\"training_metrics.json\")]  \n",
    ")\n",
    "\n",
    "train_results = trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ESM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
